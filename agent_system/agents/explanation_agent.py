import json
import os
from typing import List, Optional
from groq import Groq
from ..schemas import QueryIntentSchema, RetrievedLoanCaseSchema, FinalResponseSchema
from ..prompts import EXPLANATION_PROMPT, COMPLIANCE_GUIDELINES

class ExplanationAgent:
    def __init__(self, model_name: str = "llama-3.3-70b-versatile", api_key: Optional[str] = None):
        self.model_name = model_name
        self.api_key = api_key or os.getenv('GROQ_API_KEY')
        self.client = None
        if self.api_key:
            self.client = Groq(api_key=self.api_key)
        else:
            print("[WARN] Groq API Key missing. ExplanationAgent will use placeholder logic.")

    def generate_explanation(self, query: str, intent: QueryIntentSchema, cases: List[RetrievedLoanCaseSchema]) -> FinalResponseSchema:
        if not self.client or not cases:
            return self._generate_placeholder_response(query, intent, cases)

        # 1. Prepare context
        context_parts = []
        for i, case in enumerate(cases, 1):
            context_parts.append(f"Case {i}: Customer {case.customer_name}, Status: {case.approval_status}, Amount: INR {case.loan_amount}")
            # Add relevant metadata from original_data
            for key in ['Applicant_Income', 'CIBIL_Score', 'Debt_to_Income_Ratio', 'Loan_Purpose']:
                if key in case.original_data:
                    context_parts.append(f"  - {key}: {case.original_data[key]}")
        
        context_str = "\n".join(context_parts)

        # 2. Call LLM
        prompt = EXPLANATION_PROMPT.format(
            query=query,
            intent=intent.intent.value,
            tone=intent.compliance_tone.value,
            context=context_str,
            compliance_guidelines=COMPLIANCE_GUIDELINES
        )

        try:
            response = self.client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "You are a specialized Loan Compliance Analyst."},
                    {"role": "user", "content": prompt}
                ],
                model=self.model_name,
                temperature=0.1,
                response_format={"type": "json_object"}
            )
            
            data = json.loads(response.choices[0].message.content)
            
            return FinalResponseSchema(
                query=query,
                intent=intent.intent,
                retrieved_case_count=len(cases),
                summary=data.get("summary", "Analysis complete."),
                evidence_points=data.get("evidence_points", []),
                risk_notes=data.get("risk_notes", []),
                compliance_disclaimer=data.get("compliance_disclaimer", "Generated by AI. Verify with official records."),
                structured_data=cases
            )

        except Exception as e:
            print(f"[ERROR] ExplanationAgent LLM Error: {e}")
            return self._generate_placeholder_response(query, intent, cases)

    def _generate_placeholder_response(self, query: str, intent: QueryIntentSchema, cases: List[RetrievedLoanCaseSchema]) -> FinalResponseSchema:
        summary = f"Retrieved {len(cases)} cases relevant to your query. "
        if not cases:
            summary += "No specific historical matches found to analyze."
        
        return FinalResponseSchema(
            query=query,
            intent=intent.intent,
            retrieved_case_count=len(cases),
            summary=summary,
            evidence_points=[f"Case {c.customer_name}: Status {c.approval_status}" for c in cases[:3]],
            risk_notes=["Advanced risk analysis requires Groq API."],
            compliance_disclaimer="Generated by AI (Fallback Mode). Verify with official records.",
            structured_data=cases
        )
